# Stealthy-backdoor-attacks-the-threat-is-something-you-can-not-hear
The purpose of this graduation thesis is to provide a systematization of knowledge that explores audio backdoor attacks perpetrated through malicious triggers and elaborates defence models to mitigate them.

## Steps to follow to run the code correctly
1. Download the GSCD dataset: [speech_commands_v0.01.tar.gz](http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz)
2. Run the Notebook called "*Import_dataset_and_preprocessing.ipynb" to obtain the clean and preprocessed data
3. Run the Notebook called "cleanModels.ipynb" to train the clean models and save the best run. This information will be needed later. However, if you don't want to train the models from scratch, you can download the train checkpoints and best epoch at the following link: [experiments_cleanData](https://drive.google.com/drive/folders/10mDjP7MVyd5HTl2vyJl9YFnGco1c0cFp?usp=sharing)
4. Run the different notebooks that entail the train of the poisoned models and the different prevention techniques used over those models, for each trigger developed. The triggers developed in this study are the inaudible trigger ("Inaudible trigger.ipynb"), the Pitch-boost trigger ("Pitch_boosting_and_PBSM_triggers.ipynb"), the PBSM trigger ("Pitch_boosting_and_PBSM_triggers.ipynb"), the VSVC ("VSVC_trigger.ipynb") and the PIBA trigger ("PIBA_trigger.ipynb"). You can download the train checkpoints and best epoch of the training of the poison model at the link [experiments_poisonData](https://drive.google.com/drive/folders/1d96YQXXXpghuYOfwRPtgJhiNXlj1KIua?usp=sharing), while you can download them for the prevention at [experimentsPrevention](https://drive.google.com/drive/folders/1O3JkJBUpqqM7KV1PT1D0u18AO3nis79T?usp=sharing)
